\section{Theoretical Properties}\label{sec:theory}
In this section, we analyze asymptotic properties of adaptive thresholding average modified periodograms. First we need to present the bound for bias in the average modified periodogram and variance estimator. Then we build concentration inequality for estimators of both of them. 


\subsection{Bounding the Bias}
Although the modified periodograms $H(\omega_k), k\in \mathcal{B}_j$  are asymptotically independent, and behave like i.i.d., we need to quantify the bias from two sources. One is from the gap between the finite sample to the limiting distribution; the other is from the fact that the limiting distributions are not exactly identical. In this section, we list the results of bounding the bias for both smoothing modified periodograms and variance estimator. \par 

Our process requires some conditions in the minimal value of diagonal of spectral density. 
\begin{assumption}
$\min_{r=1}^p f_{rr}(\omega_j) \ge \phi_0 > 0$.
\end{assumption}
For simplicity we give a deterministic lower bound for diagonal elements in spectral density. 

\paragraph{Bias for Smoothing Modified Periodogram} Similar to \cite{sun2018large}, two quantities are needed that capture the strength of temporal and contemporaneous dependence in the multivariate time series $\{X_t\}_{t \in \mathbb{Z}}$ , which are 
\begin{eqnarray}
\Omega_{n} = \max_{1 \le r,s \le p} \sum_{\ell=-n}^n |\ell| |\Gamma_{rs}(\ell)|, ~~~~ L_n = \max_{1 \le r,s \le p}\sum_{|\ell|>n} |\Gamma_{rs}(\ell)|.
\end{eqnarray}
\begin{lem}
\label{lemma:bound_deviation}
For any $j\in F_n$, $1\le r, s\le p$, 
\begin{equation}
\begin{aligned}
&\max\left\{\left|\mathbb{E}[{\bf Re}(g_{rs}(\omega_j))] - {\bf Re}(f_{rs}(\omega_j))\right|, \left|\mathbb{E}[{\bf Im}(g_{rs}(\omega_j))] - {\bf Im}(f_{rs}(\omega_j))\right|\right\} \le B_f,
\end{aligned}
\end{equation}
where $B_f = \frac{m}{n}\Omega_n + \frac{1}{2\pi}\left(\frac{\Omega_n}{n}+L_n\right) +\frac{\Omega_n}{2\pi n}$.
\end{lem}
The technique for proof starts with the triangular inequality, 
\begin{equation}
\begin{aligned}
&\left|\E[{\bf Re}(g_{rs}(\omega_j))] - {\bf Re}(f_{rs}(\omega_j))\right| \\
&\le \left|\E[{\bf Re}(g_{rs}(\omega_j))] - \E[{\bf Re}(\hat{f}_{rs}(\omega_j))]\right|+\left|\E[{\bf Re}(\hat{f}_{rs}(\omega_j))] - {\bf Re}(f_{rs}(\omega_j))\right|, 
\end{aligned}
\end{equation}
where the bound for the second part is already shown in \cite{sun2018large}, and the first part of above inequality we can handle properties of toeplitz matrices. We defer the detailed proof to Appendix. 
\paragraph{Bias for Variance Estimation}
\begin{lem}
\label{lemma:theta_bias}
\begin{equation}
\begin{aligned}
&\max\left\{\left|\mathbb{E} \hat{\theta}^{(r)}_{j,rs} - \theta^{(r)}_{j, rs}\right|,  \left|\mathbb{E} \hat{\theta}^{(i)}_{j,rs} - \theta^{(i)}_{j, rs}\right|\right\}\le B_\theta,
\end{aligned}
\end{equation}
where $B_\theta = 2\max (f_{rr}(\omega_j),f_{ss}(\omega_j))(\delta_1+\delta_2)+\delta_1^2+\delta_2^2+\frac{\Omega_n^2}{\pi^2n^2}$,
and 
\begin{equation}
\label{eq:def_delta12}
\begin{aligned}
&\delta_1 = \frac{\Omega_n}{2n\pi}+\frac{\sqrt{2}}{2\pi}\frac{m\Omega_n}{n}+ \frac{1}{2\pi}\left(\frac{\Omega_n}{n} + L_n\right) \\
&\delta_2=\frac{\Omega_n}{2n\pi}+ \frac{1}{2\pi}\left(\frac{\Omega_n}{n} + L_n\right).
\end{aligned}
\end{equation}
\end{lem}
\begin{remark}
Assuming $\Omega_n,  f_{rr}$ is bounded, then the bias in variance estimation has the same order of bias for estimator $g_{rs}(\omega_j)$: $\mathcal{O}(m/n)$. 
\end{remark}
The proof is deferred to Appendix. 
Based on the bound for variance estimation, we here present another useful result. Since our intuition is that asymptotically modified periodograms are behaving like i.i.d. within $\mathcal{B}_j$, we expect that   
\begin{equation}
\begin{aligned}
& \Var({\bf Re}(g_{rs}(\omega_j))) \approx \frac{1}{m} \theta^{(r)}_{j, rs}\\ 
& \Var({\bf Im}(g_{rs}(\omega_j))) \approx \frac{1}{m} \theta^{(i)}_{j, rs}.
\end{aligned}
\end{equation}
The following lemma justifies and quantifies the above intuition. 
\begin{lem}
For $1\le r, s\le p$, 
\label{lemma: variance_ratio_error}
\begin{equation}
\begin{aligned}
& \frac{1}{m}(1-B_\delta) \le \min\left\{\left|\frac{\Var({\bf Re}(g_{rs}(\omega_j)))}{\theta^{(r)}_{j, rs}}\right|, \left|\frac{\Var({\bf Im}(g_{rs}(\omega_j)))}{\theta^{(i)}_{j, rs}}\right|\right\}\\
& \le \max\left\{\left|\frac{\Var({\bf Re}(g_{rs}(\omega_j)))}{\theta^{(r)}_{j, rs}}\right|, \left|\frac{\Var({\bf Im}(g_{rs}(\omega_j)))}{\theta^{(i)}_{j, rs}}\right|\right\} \le \frac{1}{m}(1+B_\delta),
\end{aligned}
\end{equation}
where $B_\delta = 4\delta_1/\phi_0 + 3\delta_1^2/\phi_0^2$, $\delta_1, \delta_2$ follow the definition in Lemma \ref{lemma:theta_bias}. 
\end{lem}


\subsection{Deviation Bound} 
In the previous section,  we have shown the upper bound for bias for $g_{rs}(\omega_j)$, $\hat{\theta}^{(r)}_{j, rs}$ and $\hat{\theta}^{(i)}_{j, rs}$. In this section, we will build the non-asymptotic analysis for those estimators. The non-asymptotic analysis will lead to the
main theory for consistency of our adaptive thresholding estimators. 


\begin{lem}
\label{lemma: deviation_variance}
For any positive number $\eta>0$, there exit constants $c_1, c_2$ s.t.
\begin{equation}
\begin{aligned}
& \mathbb{P}\left(\left|\hat{\theta}^{(r)}_{j, rs} - \theta^{(r)}_{j, rs}\right|\ge  
B_\theta + \eta \right) \le  c_1\exp(-c_2m\min\left(\eta, \eta^2\right)), \\ 
& \mathbb{P}\left(\left|\hat{\theta}^{(i)}_{j, rs} - \theta^{(i)}_{j, rs}\right|\ge  
B_\theta + \eta \right) \le  c_1\exp(-c_2m\min\left(\eta, \eta^2\right)).\\ 
\end{aligned}
\end{equation}
\end{lem}
The next lemma constitutes the key element for theoretical development. It is a non-asymptotic analysis. 
\begin{lem}
\label{lemma: main_lemma}
For $j\in F_n$, and $\omega_j \notin \{0, -\pi\}$,  $1\le r, s\le p$, 
assuming $B_\delta\le 3$ and $B_\theta/\phi_0^2<1/4$, given $\eta\le 1$, there exist universal positive constants $c_1, c_2$, s.t. 
\begin{equation}
\begin{aligned}
& \Prob\left(\left|\frac{{\bf Re}(g_{rs}(\omega_j)) - {\bf Re}(f_{rs}(\omega_j))}{\sqrt{\hat{\theta}^{(r)}_{j,rs}}}\right| \ge \frac{B_f}{\phi_0}+\eta\right)\le c_1\exp(-c_2\min(\eta^2 m, \eta \sqrt{m})),\\
& \Prob\left(\left|\frac{{\bf Im}(g_{rs}(\omega_j)) - {\bf Im}(f_{rs}(\omega_j))}{\sqrt{\hat{\theta}^{(i)}_{j,rs}}}\right| \ge \frac{B_f}{\phi_0}+\eta\right)\le c_1\exp(-c_2\min(\eta^2 m, \eta \sqrt{m})).
\end{aligned}
\end{equation}
\end{lem}
\begin{remark}
The conditions like $B_\delta\le 3$ and $B_\theta/\phi_0^2<1/4$ are set for convenience of proof. In the later main results section, asymptotically, they both go to zero. 
\end{remark}

\begin{proof}
We will focus on the proof for the real part. First we handle the bias. 
Define event $\mathcal{A}_j$ and $\mathcal{B}_j$ as 
\begin{equation}
\begin{aligned}
& \mathcal{A}_j = \{\hat{\theta}^{(r)}_{j, rs}\le (4 - B_\theta/\phi_0^2) \theta^{(r)}_{j,rs} \},\\
& \mathcal{B}_j = \{\hat{\theta}^{(r)}_{j, rs}\ge (1/4 + B_\theta/\phi_0^2) \theta^{(r)}_{j, rs} \}.
\end{aligned}
\end{equation}
Given lemma \ref{lemma: deviation_variance} and the fact that $\theta^{(r)}_{j, rs}$ is at the same order of $f_{rr}(\omega_j)f_{ss}(\omega_j)$:
\begin{equation}
f_{rr}(\omega_j)f_{ss}(\omega_j)\le \theta^{(r)}_{j, rs}\le  2f_{rr}(\omega_j)f_{ss}(\omega_j). 
\end{equation}
We can show that there exist universal constants $c_1, c_2$ only depending on $\phi_0$
\begin{equation}
\begin{aligned}
&\mathbb{P} (\mathcal{A}_j^c) \le \mathbb{P}\left(|\hat{\theta}^{(r)}_{j, rs} - \theta^{(r)}_{j, rs}|\ge (3 +B_\theta/\phi_0^2 )f_{rr}(\omega_j)f_{ss}(\omega_j)\right)\\
& \le c_1\exp\{-c_2m\}.
\end{aligned}
\end{equation}
Similarly we can obtain the same bound for $\mathbb{P}(\mathcal{B}_j^c)$. From now on we restrict our analysis to the event $\mathcal{A}_j$ and $\mathcal{B}_j$. \par 
By triangular inequality,  
\begin{equation}
\begin{aligned}
& \left|\frac{{\bf Re}(g_{rs}(\omega_j)) - {\bf Re}(f_{rs}(\omega_j))}{\sqrt{\hat{\theta}^{(r)}_{j,rs}}}\right| \\
& \le \left|\frac{{\bf Re}(g_{rs}(\omega_j)) - \E {\bf Re}(g_{rs}(\omega_j))}{\sqrt{\hat{\theta}^{(r)}_{j,rs}}}\right|\\
& +  \left|\frac{\E {\bf Re}(g_{rs}(\omega_j)) -{\bf Re}(f_{rs}(\omega_j))}{\sqrt{\hat{\theta}^{(r)}_{j,rs}}}\right|. 
\end{aligned}
\end{equation}
Noticing on event $\mathcal{B}_j$, 
\begin{equation}
 \left|\frac{\E {\bf Re}(g_{rs}(\omega_j)) -{\bf Re}(f_{rs}(\omega_j))}{\sqrt{\hat{\theta}^{(r)}_{j,rs}}}\right|\le 2B_f/\phi_0,
\end{equation}
which indicates that 

\begin{equation}
\begin{aligned}
& \Prob\left(\left|\frac{{\bf Re}(g_{rs}(\omega_j)) - {\bf Re}(f_{rs}(\omega_j))}{\sqrt{\hat{\theta}^{(r)}_{j,rs}}}\right| \ge \frac{B_f}{\phi_0}+\eta\right) \\
& \le \Prob\left(\left|\frac{{\bf Re}(g_{rs}(\omega_j)) - \E {\bf Re}(g_{rs}(\omega_j))}{\sqrt{\hat{\theta}^{(r)}_{j,rs}}}\right| \ge \eta\right) .
\end{aligned}
\end{equation}
On event  $\mathcal{A}_j$, 
\[
\sqrt{\frac{\hat{\theta}^{(r)}_{j, rs}}{\theta^{(r)}_{j, rs}}} \le 2. 
\]

We write the left part of the result for the real part as  
\begin{equation}
\begin{aligned}
& \left|\frac{{\bf Re}(g_{rs}(\omega_j)) - {\bf Re}(f_{rs}(\omega_j))}{\sqrt{\hat{\theta}^{(r)}_{j,rs}}}\right|  \\
& = \left|\frac{{\bf Re}(g_{rs}(\omega_j)) - {\bf Re}(f_{rs}(\omega_j))}{\sqrt{\Var({\bf Re}(g_{rs}(\omega_j)))}}\right|\\
& \times \left|\sqrt{\frac{\Var(g_{rs}(\omega_j))}{\theta^{(r)}_{rs}}}\right| \times \left|\sqrt{\frac{\theta^{(r)}_{rs}}{\hat{\theta}^{(r)}_{rs}}}\right|
\end{aligned}
\end{equation}


Since we assume $B_\delta\le 3$, 
\[
\left|\frac{\sqrt{\Var(g_{rs}(\omega_j))}}{\sqrt{\theta^{(r)}_{rs}}}\right| \le \sqrt{(1+B_\delta)m}\le 2\sqrt{m}. 
\]
Therefore, on $\mathcal{A}_j$, we have 
\begin{equation}
\begin{aligned}
& \Prob\left(\left|\frac{{\bf Re}(g_{rs}(\omega_j)) - {\bf Re}(f_{rs}(\omega_j))}{\sqrt{\hat{\theta}^{(r)}_{j,rs}}}\right| \ge \frac{B_f}{\phi_0}+\eta\right) \\
& \le \Prob\left(\left|\frac{{\bf Re}(g_{rs}(\omega_j)) - \E {\bf Re}(f_{rs}(\omega_j))}{\sqrt{\Var({\bf Re}(g_{rs}(\omega_j)))}}\right| \ge 4\eta\sqrt{m} \right)\\
& \le c_1\exp(-c_2\min(\eta^2 m, \eta \sqrt{m})), 
\end{aligned}
\end{equation}
where the last inequality comes from lemma \ref{lemma: variant_hanson_wright} and the fact that we can write 
${\bf Re}(f_{rs}(\omega_j))$ as quadratic function of Gaussian random variables as shown in \cite{sun2018large}. 
\end{proof}



\subsection{Main Results}
\subsection{Sparse Class}
In order to analyze the effectiveness of this estimator like consistency in $L_2$ norm, we require the following sparse class which is inspired by \cite{bickel2008covariance}: for frequency $\omega_j$, 
\begin{equation}
\mathcal{U}(q, c_0(p), \omega) = \left\{f(\omega): \sum_{s=1}^p |f_{rs}(\omega)|^q \le c_0(p) ~\text{for all}~ r\right \}. 
\end{equation}
\cite{sun2018large} shows that a generalized thresholding estimator can achieve $L_2$ and Frobenius norm estimation consistency. For adaptive thresholding, we follow the analogy of \cite{cai2011adaptive}, defining the following sparse class:
\begin{equation}
\begin{aligned}
\label{eq:sparse_class}
\mathcal{U}^a(q, c_0(p), \omega) = \left\{f(\omega): \max_{r=1}^p\sum_{s=1}^p (f_{rr}(\omega)f_{ss}(\omega))^{(1-q)/2} |f_{rs}(\omega)|^q \le c_0(p)\right \}.  
\end{aligned}
\end{equation}
There are detailed discussions by \cite{cai2011adaptive}
on how $\mathcal{U}^a$ is compared to $\mathcal{U}$. Assuming $\max_{r=1}^n f_{rr}(\omega_j)\le M$, is bounded, 
$\mathcal{U}(q, c_0(p), \omega) \subset \mathcal{U}^a(q, c_0(p), \omega) $. Although \cite{sun2018large} lets the $\max_{r=1}^p f_{rr}(\omega_j)$ grow with dimension but the rate for growth must be controlled in order to make sure that the thresholding value go to zero asymptotically. While in this paper,  the adaptive thresholding estimator does not put any constraint on the growth rate for this statistic, but instead, we need a lower bound for $\min_{r=1}^p f_{rr}(\omega_j)$ or control the decay rate to zero. But this lower bound only occurs in the bias term. 

\subsection{Consistency Under Weak Sparsity}

\begin{prop}
\label{prop: gauss_prop}
Assume ${X}_t, t=1,\ldots,n$, are $n$ consecutive observations from a stable Gaussian time series satisfying Assumption \ref{assumption:finite_auto}, and consider a single Fourier frequency $\omega_j \in [-\pi, \pi)$ and $\omega_j \neq 0$. 
For any $m $ satisfying $m \precsim n/ \Omega_n(f)$ and $m \succsim c_0^2(p)\log p$, and a large enough $R > 0$,  
there exist universal constants $c_1, c_2 > 0$ such that choosing a threshold 
\begin{equation}
\label{eq:threshold_value}
\lambda = R c_0(p)\sqrt{\frac{\log p}{m}} +2B_f/\phi_0, 
\end{equation}
where $B_f = \frac{m}{n}\Omega_n(f_X) + \frac{1}{2\pi}\left(\frac{\Omega_n(f_X)}{n}+L_n(f_X)\right) +\frac{\Omega_n}{2\pi n}$, 
assuming $f(\omega_j)\in \mathcal{U}^a(q, c_0(p), \omega)$, 
the estimation error of adaptive thresholding average modified periodogram satisfies 
\begin{equation}
\begin{aligned}
\mathbb{P}\left(\left\|T_{\lambda}(\hat{f}(\omega_j)) - f(\omega_j)\right\|\ge 7 \lambda^{(1-q)/2} \right)
\le c_1 \exp\left[-(c_2 R^2-2)\log p\right]. \nonumber
\end{aligned}
\end{equation}
\end{prop}

\begin{proof}
The logic for proof is almost the same as proof for consistency for operator norm appears in \cite{sun2018large}. Using the concentration inequality introduced by Lemma \ref{lemma: main_lemma}  with the weakly sparse class coefficient, we can almost use exactly the same argument to finish the proof. So we omit the the details here. For those type of proof, the difficulty mainly lies in building the concentration inequality as Lemma \ref{lemma: main_lemma}. 
\end{proof}

\begin{remark}
Although $B_f$ seems to have a complicated form,  in many linear processes,  as shown in \cite{sun2018large},  $\Omega_n$ is uniformly bounded. Also, if we set $m=\mathcal{O}(\sqrt{n})$, then $\log p/m \rightarrow 0$ if $p = \mathcal{O}(n^\delta)$ for any positive delta which is the same as modern high dimensional setting. Then it is not hard to find a sequence of thresholding value $\lambda$ go to zero, as $n\rightarrow \infty$ and $p\rightarrow \infty$, 
\end{remark}











