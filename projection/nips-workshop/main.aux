\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{wright2009robust,buhler2002finding,allen2014sparse,bingham2001random,fradkin2003experiments,halko2011finding}
\citation{papadimitriou2000latent}
\citation{sahin2005prism,kaski1998dimensionality}
\citation{liu2006random}
\citation{barron2009automatic}
\citation{matsumoto1998mersenne}
\citation{johnson1984extensions}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {paragraph}{Dimension Reduction Map}{1}{section*.2}}
\citation{achlioptas2003database}
\citation{li2006very}
\citation{ailon2006approximate}
\citation{krahmer2011new,nguyen2009fast,tropp2011improved,halko2011finding,ailon2013almost,liberty2009accelerated,sarlos2006improved}
\citation{kolda2009tensor}
\newlabel{expected-isometry}{{1}{2}{Dimension Reduction Map}{Item.1}{}}
\newlabel{expected-isometry@cref}{{[enumi][1][]1}{[1][2][]2}}
\newlabel{vanishing-variance}{{2}{2}{Dimension Reduction Map}{Item.2}{}}
\newlabel{vanishing-variance@cref}{{[enumi][2][]2}{[1][2][]2}}
\newlabel{db-friendly}{{3}{2}{Dimension Reduction Map}{Item.3}{}}
\newlabel{db-friendly@cref}{{[enumi][3][]3}{[1][2][]2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Notation}{2}{subsection.1.1}}
\newlabel{khatri-rao}{{1.1}{2}{Notation}{equation.1.1}{}}
\newlabel{khatri-rao@cref}{{[equation][1][1]1.1}{[1][2][]2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Tensor Random Projection}{2}{section.2}}
\newlabel{eq:TRP}{{2.1}{2}{Tensor Random Projection}{equation.2.1}{}}
\newlabel{eq:TRP@cref}{{[equation][1][2]2.1}{[1][2][]2}}
\citation{achlioptas2003database}
\citation{li2006very}
\@writefile{toc}{\contentsline {paragraph}{Variance Reduction}{3}{section*.3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Main Theory}{3}{section.3}}
\newlabel{lemma: norm-preserve}{{3.1}{3}{}{thm.3.1}{}}
\newlabel{lemma: norm-preserve@cref}{{[lem][1][3]3.1}{[1][3][]3}}
\newlabel{eq:lemma-invariant-length-statement}{{3.1}{3}{}{equation.3.1}{}}
\newlabel{eq:lemma-invariant-length-statement@cref}{{[equation][1][3]3.1}{[1][3][]3}}
\newlabel{lemma:variance}{{3.2}{3}{}{thm.3.2}{}}
\newlabel{lemma:variance@cref}{{[lem][2][3]3.2}{[1][3][]3}}
\newlabel{prop: N-2-bound}{{3.3}{3}{}{thm.3.3}{}}
\newlabel{prop: N-2-bound@cref}{{[prop][3][3]3.3}{[1][3][]3}}
\newlabel{eq:lemma-invariant-length-statement}{{3.1}{3}{}{equation.3.1}{}}
\newlabel{eq:lemma-invariant-length-statement@cref}{{[equation][1][3]3.1}{[1][3][]3}}
\citation{achlioptas2003database}
\citation{li2006very}
\citation{achlioptas2003database}
\citation{li2006very}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces RMSE for the estimate of the pairwise inner product of the MNIST data, where standard error is in the parentheses.\relax }}{4}{table.caption.5}}
\newlabel{tbl:mnist_inner_prod}{{1}{4}{RMSE for the estimate of the pairwise inner product of the MNIST data, where standard error is in the parentheses.\relax }{table.caption.5}{}}
\newlabel{tbl:mnist_inner_prod@cref}{{[table][1][]1}{[1][4][]4}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiment}{4}{section.4}}
\newlabel{sec:simulation}{{4}{4}{Experiment}{section.4}{}}
\newlabel{sec:simulation@cref}{{[section][4][]4}{[1][4][]4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Isometry quality for simulated and MNIST data. The left two plots show results for Gaussian and Very Sparse RP, TRP, TRP(5) respectively applied to $n = 20$ standard normal data vectors in $\mathbb  {R}^{2500}$. The right two plots show the same for 50 MNIST image vectors in $\mathbb  {R}^{784}$. The dashed line shows the error two standard deviations from the average ratio.\relax }}{4}{figure.caption.4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:main}{{1}{4}{Isometry quality for simulated and MNIST data. The left two plots show results for Gaussian and Very Sparse RP, TRP, TRP(5) respectively applied to $n = 20$ standard normal data vectors in $\mathbb {R}^{2500}$. The right two plots show the same for 50 MNIST image vectors in $\mathbb {R}^{784}$. The dashed line shows the error two standard deviations from the average ratio.\relax }{figure.caption.4}{}}
\newlabel{fig:main@cref}{{[figure][1][]1}{[1][4][]4}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{4}{section.5}}
\bibdata{biblio}
\bibcite{achlioptas2003database}{{1}{}{{}}{{}}}
\bibcite{ailon2006approximate}{{2}{}{{}}{{}}}
\bibcite{ailon2013almost}{{3}{}{{}}{{}}}
\bibcite{allen2014sparse}{{4}{}{{}}{{}}}
\bibcite{barron2009automatic}{{5}{}{{}}{{}}}
\bibcite{bingham2001random}{{6}{}{{}}{{}}}
\bibcite{buhler2002finding}{{7}{}{{}}{{}}}
\bibcite{de2000multilinear}{{8}{}{{}}{{}}}
\bibcite{fradkin2003experiments}{{9}{}{{}}{{}}}
\bibcite{halko2011finding}{{10}{}{{}}{{}}}
\bibcite{johnson1984extensions}{{11}{}{{}}{{}}}
\bibcite{kaski1998dimensionality}{{12}{}{{}}{{}}}
\bibcite{kolda2009tensor}{{13}{}{{}}{{}}}
\bibcite{krahmer2011new}{{14}{}{{}}{{}}}
\bibcite{li2006very}{{15}{}{{}}{{}}}
\bibcite{liberty2009accelerated}{{16}{}{{}}{{}}}
\bibcite{liu2006random}{{17}{}{{}}{{}}}
\bibcite{matsumoto1998mersenne}{{18}{}{{}}{{}}}
\bibcite{nguyen2009fast}{{19}{}{{}}{{}}}
\bibcite{papadimitriou2000latent}{{20}{}{{}}{{}}}
\bibcite{rudelson2013hanson}{{21}{}{{}}{{}}}
\bibcite{sahin2005prism}{{22}{}{{}}{{}}}
\bibcite{sarlos2006improved}{{23}{}{{}}{{}}}
\bibcite{tropp2011improved}{{24}{}{{}}{{}}}
\bibcite{wang2015fast}{{25}{}{{}}{{}}}
\bibcite{woodruff2014sketching}{{26}{}{{}}{{}}}
\bibcite{wright2009robust}{{27}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{Appendix \numberline {A}Proof for Main Theorems}{7}{Appendix.1.A}}
\newlabel{sec:appendix_proof}{{A}{7}{Proof for Main Theorems}{Appendix.1.A}{}}
\newlabel{sec:appendix_proof@cref}{{[section][1][]A}{[1][7][]7}}
\newlabel{eq:row-length}{{A.1}{7}{Proof for Lemma \ref {lemma: norm-preserve}}{equation.1.A.1}{}}
\newlabel{eq:row-length@cref}{{[equation][1][1]A.1}{[1][7][]7}}
\newlabel{lemma:inner-product}{{A.1}{8}{}{thm.1.A.1}{}}
\newlabel{lemma:inner-product@cref}{{[lem][1][1]A.1}{[1][8][]8}}
\newlabel{eq:inner-bound}{{A.1}{8}{}{equation.1.A.1}{}}
\newlabel{eq:inner-bound@cref}{{[equation][1][1]A.1}{[1][8][]8}}
\newlabel{def:generalized-sub-exponential-mc}{{A.1}{9}{}{definition.1.A.1}{}}
\newlabel{def:generalized-sub-exponential-mc@cref}{{[definition][1][1]A.1}{[1][9][]9}}
\newlabel{eq:constant_in-sub-exponential}{{A.2}{10}{Proof for Proposition \ref {prop: N-2-bound}}{equation.1.A.2}{}}
\newlabel{eq:constant_in-sub-exponential@cref}{{[equation][2][1]A.2}{[1][10][]10}}
\@writefile{toc}{\contentsline {section}{Appendix \numberline {B}More Simulation Results}{11}{Appendix.1.B}}
\newlabel{appendix:more_result}{{B}{11}{More Simulation Results}{Appendix.1.B}{}}
\newlabel{appendix:more_result@cref}{{[section][2][]B}{[1][11][]11}}
\@writefile{toc}{\contentsline {paragraph}{Pairwise Distance Estimation}{11}{section*.11}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Average ratio of the pairwise distance for simulation data using Gaussian RP: \textit  {The plots correspond to the simulation for Gaussian RP, TRP, TRP(5) respectively with $n = 20, d = 2500, 10000, 40000$ and each data vector comes from $N(\mathbf  {0}, \mathbf  {I})$. The dashed line represents the error bar 2 standard deviation away from the average ratio.}\relax }}{11}{figure.caption.12}}
\newlabel{fig:gaussian}{{2}{11}{Average ratio of the pairwise distance for simulation data using Gaussian RP: \textit {The plots correspond to the simulation for Gaussian RP, TRP, TRP(5) respectively with $n = 20, d = 2500, 10000, 40000$ and each data vector comes from $N(\mathbf {0}, \mathbf {I})$. The dashed line represents the error bar 2 standard deviation away from the average ratio.}\relax }{figure.caption.12}{}}
\newlabel{fig:gaussian@cref}{{[figure][2][]2}{[1][11][]11}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Average ratio of the pairwise distance for simulation data using Sparse RP: \textit  {The plots correspond to the simulation for Sparse RP, TRP, TRP(5) respectively with $n = 20, d = 2500, 10000, 40000$ and each data vector comes from $N(\mathbf  {0}, \mathbf  {I})$. The dashed line represents the error bar 2 standard deviation away from the average ratio.}\relax }}{11}{figure.caption.13}}
\newlabel{fig:sparse}{{3}{11}{Average ratio of the pairwise distance for simulation data using Sparse RP: \textit {The plots correspond to the simulation for Sparse RP, TRP, TRP(5) respectively with $n = 20, d = 2500, 10000, 40000$ and each data vector comes from $N(\mathbf {0}, \mathbf {I})$. The dashed line represents the error bar 2 standard deviation away from the average ratio.}\relax }{figure.caption.13}{}}
\newlabel{fig:sparse@cref}{{[figure][3][]3}{[1][11][]11}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Average ratio of the pairwise distance for simulation data using Very Sparse RP: \textit  {The plots correspond to the simulation for Very Sparse RP, TRP, TRP(5) respectively with $n = 20, d = 2500, 10000, 40000$ and each data vector comes from $N(\mathbf  {0}, \mathbf  {I})$. The dashed line represents the error bar 2 standard deviation away from the average ratio.}\relax }}{11}{figure.caption.14}}
\newlabel{fig:very_sparse}{{4}{11}{Average ratio of the pairwise distance for simulation data using Very Sparse RP: \textit {The plots correspond to the simulation for Very Sparse RP, TRP, TRP(5) respectively with $n = 20, d = 2500, 10000, 40000$ and each data vector comes from $N(\mathbf {0}, \mathbf {I})$. The dashed line represents the error bar 2 standard deviation away from the average ratio.}\relax }{figure.caption.14}{}}
\newlabel{fig:very_sparse@cref}{{[figure][4][]4}{[1][11][]11}}
\@writefile{toc}{\contentsline {paragraph}{Pairwise Cosine Similarity Estimation}{11}{section*.16}}
\citation{halko2011finding,woodruff2014sketching}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Average ratio of the pairwise distance for simulation data using: \textit  {The plots correspond to the simulation for Gaussian, Sparase, Very Sparse RP, TRP, TRP(5) respectively with $n = 20, d = d_1d_2d_3 = 50 \times 50 \times 50 = 125000$ and each data vector comes from $N(\mathbf  {0}, \mathbf  {I})$. The dashed line represents the error bar 2 standard deviation away from the average ratio.}\relax }}{12}{figure.caption.15}}
\newlabel{fig:triple_krao}{{5}{12}{Average ratio of the pairwise distance for simulation data using: \textit {The plots correspond to the simulation for Gaussian, Sparase, Very Sparse RP, TRP, TRP(5) respectively with $n = 20, d = d_1d_2d_3 = 50 \times 50 \times 50 = 125000$ and each data vector comes from $N(\mathbf {0}, \mathbf {I})$. The dashed line represents the error bar 2 standard deviation away from the average ratio.}\relax }{figure.caption.15}{}}
\newlabel{fig:triple_krao@cref}{{[figure][5][]5}{[1][11][]12}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces RMSE for the estimate of the pairwise inner product of the simulation data ($d = 10000, k = 50, n = 100 $), where standard error is in the parentheses. \relax }}{12}{table.caption.17}}
\newlabel{tbl:sim_inner_prod}{{2}{12}{RMSE for the estimate of the pairwise inner product of the simulation data ($d = 10000, k = 50, n = 100 $), where standard error is in the parentheses. \relax }{table.caption.17}{}}
\newlabel{tbl:sim_inner_prod@cref}{{[table][2][]2}{[1][12][]12}}
\@writefile{toc}{\contentsline {section}{Appendix \numberline {C}Application: Sketching}{12}{Appendix.1.C}}
\newlabel{appendix:sketching}{{C}{12}{Application: Sketching}{Appendix.1.C}{}}
\newlabel{appendix:sketching@cref}{{[section][3][]C}{[1][12][]12}}
\citation{de2000multilinear,wang2015fast}
\citation{kolda2009tensor}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Tensor Sketching with Variance Reduction\relax }}{13}{algorithm.1}}
\newlabel{alg:var-red-structure-sketching}{{1}{13}{Tensor Sketching with Variance Reduction\relax }{algorithm.1}{}}
\newlabel{alg:var-red-structure-sketching@cref}{{[algorithm][1][]1}{[1][12][]13}}
\@writefile{toc}{\contentsline {paragraph}{Experimental Setup}{13}{section*.18}}
\@writefile{toc}{\contentsline {paragraph}{Result}{13}{section*.19}}
\@writefile{toc}{\contentsline {section}{Appendix \numberline {D}Technical Lemmas}{13}{Appendix.1.D}}
\citation{rudelson2013hanson}
\citation{buhler2002finding}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Relative Error for the low-rank tensor unfolding approximation: \textit  {we compare the relative errors for low-rank tensor approximation with different input size: 2-D ($900 \times 900$), 3-D ($400 \times 400 \times 400$), 4-D ($100 \times 100 \times 100 \times 100$). In each setting, we compare the performance of Gaussian RP, TRP, and TRP(5). The dashed line stands for the 95\% confidence interval.}\relax }}{14}{figure.caption.20}}
\newlabel{fig:col_matrix}{{6}{14}{Relative Error for the low-rank tensor unfolding approximation: \textit {we compare the relative errors for low-rank tensor approximation with different input size: 2-D ($900 \times 900$), 3-D ($400 \times 400 \times 400$), 4-D ($100 \times 100 \times 100 \times 100$). In each setting, we compare the performance of Gaussian RP, TRP, and TRP(5). The dashed line stands for the 95\% confidence interval.}\relax }{figure.caption.20}{}}
\newlabel{fig:col_matrix@cref}{{[figure][6][]6}{[1][13][]14}}
\newlabel{def:sub-gaussian}{{D.1}{14}{}{definition.1.D.1}{}}
\newlabel{def:sub-gaussian@cref}{{[definition][1][4]D.1}{[1][13][]14}}
\newlabel{lemma:hanson_wright}{{D.1}{14}{}{thm.1.D.1}{}}
\newlabel{lemma:hanson_wright@cref}{{[lem][1][4]D.1}{[1][14][]14}}
\newlabel{lemma:hanson-wright-sub-exponential}{{D.2}{14}{}{thm.1.D.2}{}}
\newlabel{lemma:hanson-wright-sub-exponential@cref}{{[lem][2][4]D.2}{[1][14][]14}}
\newlabel{eq:sub-exponential-moment-condition}{{D.2}{14}{}{equation.1.D.2}{}}
\newlabel{eq:sub-exponential-moment-condition@cref}{{[lem][2][4]D.2}{[1][14][]14}}
\newlabel{lemma:hanson-wright-sub-exponential-moment}{{D.3}{14}{}{thm.1.D.3}{}}
\newlabel{lemma:hanson-wright-sub-exponential-moment@cref}{{[lem][3][4]D.3}{[1][14][]14}}
\bibstyle{plain}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
