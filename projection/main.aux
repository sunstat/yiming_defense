\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{rudelson2012row}
\citation{wright2009robust,buhler2002finding,allen2014sparse,bingham2001random,fradkin2003experiments,halko2011finding,wang2012semi,jegou2008hamming}
\citation{papadimitriou2000latent}
\citation{sahin2005prism,kaski1998dimensionality}
\citation{liu2006random}
\citation{woolfe2008fast,tropp2017practical}
\citation{yurtsever2017sketchy}
\citation{Tropp2019-SketchingScientificSimulation,sun2019low}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{eq:low_dim_mapping}{{1.1}{1}{Introduction}{equation.1.1}{}}
\newlabel{eq:low_dim_mapping@cref}{{[equation][1][1]1.1}{[1][1][]1}}
\citation{arriaga2006algorithmic}
\citation{halko2011finding}
\citation{achlioptas2003database}
\citation{li2006very,ailon2006approximate,bourgain2015toward}
\citation{rudelson2012row}
\citation{battaglino2018practical}
\citation{wang2015fast}
\citation{woodruff2014sketching}
\citation{matsumoto1998mersenne}
\newlabel{lem:gauss-rp-vector}{{1.1}{2}{\citet {arriaga2006algorithmic}}{thm.1.1}{}}
\newlabel{lem:gauss-rp-vector@cref}{{[lem][1][1]1.1}{[1][2][]2}}
\newlabel{eq:gauss_random_projection}{{1.4}{2}{\citet {arriaga2006algorithmic}}{equation.1.4}{}}
\newlabel{eq:gauss_random_projection@cref}{{[equation][4][1]1.4}{[1][2][]2}}
\newlabel{lemma:gauss-rp-matrix}{{1.2}{2}{\citet {halko2011finding}}{thm.1.2}{}}
\newlabel{lemma:gauss-rp-matrix@cref}{{[lem][2][1]1.2}{[1][2][]2}}
\newlabel{eq:gauss_col_preservation}{{1.5}{2}{\citet {halko2011finding}}{equation.1.5}{}}
\newlabel{eq:gauss_col_preservation@cref}{{[equation][5][1]1.5}{[1][2][]2}}
\@writefile{toc}{\contentsline {paragraph}{Memory Efficient Random Projection}{2}{section*.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Notation}{3}{subsection.1.1}}
\newlabel{khatri-rao}{{1.6}{3}{Notation}{equation.1.6}{}}
\newlabel{khatri-rao@cref}{{[equation][6][1]1.6}{[1][3][]3}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Tensor Random Projection}{3}{section.2}}
\citation{achlioptas2003database}
\citation{li2006very}
\newlabel{eq:TRP}{{2.1}{4}{Tensor Random Projection}{equation.2.1}{}}
\newlabel{eq:TRP@cref}{{[equation][1][2]2.1}{[1][4][]4}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Main Theory}{4}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Bias and Variance}{4}{subsection.3.1}}
\newlabel{thm: norm-preserve}{{3.1}{4}{}{thm.3.1}{}}
\newlabel{thm: norm-preserve@cref}{{[thm][1][3]3.1}{[1][4][]4}}
\newlabel{eq:lemma-invariant-length-statement}{{3.1}{4}{}{equation.3.1}{}}
\newlabel{eq:lemma-invariant-length-statement@cref}{{[equation][1][3]3.1}{[1][4][]4}}
\newlabel{thm:variance}{{3.2}{5}{}{thm.3.2}{}}
\newlabel{thm:variance@cref}{{[thm][2][3]3.2}{[1][5][]5}}
\newlabel{cor:pairwise-distance-unbias-variance}{{3.3}{5}{}{thm.3.3}{}}
\newlabel{cor:pairwise-distance-unbias-variance@cref}{{[cor][3][3]3.3}{[1][5][]5}}
\newlabel{lem:inner_product_TRP}{{3.4}{5}{}{thm.3.4}{}}
\newlabel{lem:inner_product_TRP@cref}{{[lem][4][3]3.4}{[1][5][]5}}
\citation{schacke2013kronecker}
\citation{schacke2013kronecker}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Asymptotic Behavior}{6}{subsection.3.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Finite Sample Bound?}{6}{subsection.3.3}}
\newlabel{prop: N-2-bound}{{3.5}{6}{}{thm.3.5}{}}
\newlabel{prop: N-2-bound@cref}{{[prop][5][3]3.5}{[1][6][]6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Column Space Preservation}{6}{subsection.3.4}}
\citation{achlioptas2003database}
\citation{li2006very}
\citation{achlioptas2003database}
\citation{li2006very}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiment}{7}{section.4}}
\newlabel{sec:simulation}{{4}{7}{Experiment}{section.4}{}}
\newlabel{sec:simulation@cref}{{[section][4][]4}{[1][7][]7}}
\citation{halko2011finding,woodruff2014sketching}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Isometry quality for simulated and MNIST data. The left two plots show results for Gaussian and Very Sparse RP, TRP, TRP(5) respectively applied to $n = 20$ standard normal data vectors in $\mathbb  {R}^{2500}$. The right two plots show the same for 50 MNIST image vectors in $\mathbb  {R}^{784}$. The dashed line shows the error two standard deviations from the average ratio.\relax }}{8}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:main}{{1}{8}{Isometry quality for simulated and MNIST data. The left two plots show results for Gaussian and Very Sparse RP, TRP, TRP(5) respectively applied to $n = 20$ standard normal data vectors in $\mathbb {R}^{2500}$. The right two plots show the same for 50 MNIST image vectors in $\mathbb {R}^{784}$. The dashed line shows the error two standard deviations from the average ratio.\relax }{figure.caption.2}{}}
\newlabel{fig:main@cref}{{[figure][1][]1}{[1][7][]8}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces RMSE for the estimate of the pairwise inner product of the MNIST data, where standard error is in the parentheses.\relax }}{8}{table.caption.3}}
\newlabel{tbl:mnist_inner_prod}{{1}{8}{RMSE for the estimate of the pairwise inner product of the MNIST data, where standard error is in the parentheses.\relax }{table.caption.3}{}}
\newlabel{tbl:mnist_inner_prod@cref}{{[table][1][]1}{[1][8][]8}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Application: Sketching}{8}{section.5}}
\newlabel{appendix:sketching}{{5}{8}{Application: Sketching}{section.5}{}}
\newlabel{appendix:sketching@cref}{{[section][5][]5}{[1][8][]8}}
\citation{de2000multilinear,wang2015fast}
\citation{kolda2009tensor}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Tensor Sketching with Variance Reduction\relax }}{9}{algorithm.1}}
\newlabel{alg:var-red-structure-sketching}{{1}{9}{Tensor Sketching with Variance Reduction\relax }{algorithm.1}{}}
\newlabel{alg:var-red-structure-sketching@cref}{{[algorithm][1][]1}{[1][8][]9}}
\@writefile{toc}{\contentsline {paragraph}{Experimental Setup}{9}{section*.4}}
\@writefile{toc}{\contentsline {paragraph}{Result}{10}{section*.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Relative Error for the low-rank tensor unfolding approximation: \textit  {we compare the relative errors for low-rank tensor approximation with different input size: 2-D ($900 \times 900$), 3-D ($400 \times 400 \times 400$), 4-D ($100 \times 100 \times 100 \times 100$). In each setting, we compare the performance of Gaussian RP, TRP, and $\textup  {TRP}_5$. The dashed line stands for the 95\% confidence interval.}\relax }}{10}{figure.caption.6}}
\newlabel{fig:col_matrix}{{2}{10}{Relative Error for the low-rank tensor unfolding approximation: \textit {we compare the relative errors for low-rank tensor approximation with different input size: 2-D ($900 \times 900$), 3-D ($400 \times 400 \times 400$), 4-D ($100 \times 100 \times 100 \times 100$). In each setting, we compare the performance of Gaussian RP, TRP, and $\textup {TRP}_5$. The dashed line stands for the 95\% confidence interval.}\relax }{figure.caption.6}{}}
\newlabel{fig:col_matrix@cref}{{[figure][2][]2}{[1][10][]10}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{10}{section.6}}
\bibdata{biblio.bib}
\bibcite{achlioptas2003database}{{1}{2003}{{Achlioptas}}{{}}}
\bibcite{ailon2006approximate}{{2}{2006}{{Ailon and Chazelle}}{{}}}
\bibcite{allen2014sparse}{{3}{2014}{{Allen-Zhu et~al.}}{{Allen-Zhu, Gelashvili, Micali, and Shavit}}}
\bibcite{arriaga2006algorithmic}{{4}{2006}{{Arriaga and Vempala}}{{}}}
\bibcite{battaglino2018practical}{{5}{2018}{{Battaglino et~al.}}{{Battaglino, Ballard, and Kolda}}}
\bibcite{bingham2001random}{{6}{2001}{{Bingham and Mannila}}{{}}}
\bibcite{bourgain2015toward}{{7}{2015}{{Bourgain et~al.}}{{Bourgain, Dirksen, and Nelson}}}
\bibcite{buhler2002finding}{{8}{2002}{{Buhler and Tompa}}{{}}}
\bibcite{de2000multilinear}{{9}{2000}{{De~Lathauwer et~al.}}{{De~Lathauwer, De~Moor, and Vandewalle}}}
\bibcite{fradkin2003experiments}{{10}{2003}{{Fradkin and Madigan}}{{}}}
\bibcite{halko2011finding}{{11}{2011}{{Halko et~al.}}{{Halko, Martinsson, and Tropp}}}
\bibcite{jegou2008hamming}{{12}{2008}{{Jegou et~al.}}{{Jegou, Douze, and Schmid}}}
\bibcite{kaski1998dimensionality}{{13}{1998}{{Kaski}}{{}}}
\bibcite{kolda2009tensor}{{14}{2009}{{Kolda and Bader}}{{}}}
\bibcite{li2006very}{{15}{2006}{{Li et~al.}}{{Li, Hastie, and Church}}}
\bibcite{liu2006random}{{16}{2006}{{Liu et~al.}}{{Liu, Kargupta, and Ryan}}}
\bibcite{matsumoto1998mersenne}{{17}{1998}{{Matsumoto and Nishimura}}{{}}}
\bibcite{papadimitriou2000latent}{{18}{2000}{{Papadimitriou et~al.}}{{Papadimitriou, Raghavan, Tamaki, and Vempala}}}
\bibcite{rudelson2012row}{{19}{2012}{{Rudelson}}{{}}}
\bibcite{rudelson2013hanson}{{20}{2013}{{Rudelson et~al.}}{{Rudelson, Vershynin, et~al.}}}
\bibcite{sahin2005prism}{{21}{2005}{{Sahin et~al.}}{{Sahin, Gulbeden, Emek{\c {c}}i, Agrawal, and El~Abbadi}}}
\bibcite{schacke2013kronecker}{{22}{2013}{{Sch{\"a}cke}}{{}}}
\bibcite{sun2019low}{{23}{2019}{{Sun et~al.}}{{Sun, Guo, Luo, Tropp, and Udell}}}
\bibcite{Tropp2019-SketchingScientificSimulation}{{24}{2019}{{Tropp et~al.}}{{Tropp, Yurtsever, Udell, and Cevher}}}
\bibcite{tropp2017practical}{{25}{2017}{{Tropp et~al.}}{{Tropp, Yurtsever, Udell, and Cevher}}}
\bibcite{wang2012semi}{{26}{2012}{{Wang et~al.}}{{Wang, Kumar, and Chang}}}
\bibcite{wang2015fast}{{27}{2015}{{Wang et~al.}}{{Wang, Tung, Smola, and Anandkumar}}}
\bibcite{woodruff2014sketching}{{28}{2014}{{Woodruff et~al.}}{{}}}
\bibcite{woolfe2008fast}{{29}{2008}{{Woolfe et~al.}}{{Woolfe, Liberty, Rokhlin, and Tygert}}}
\bibcite{wright2009robust}{{30}{2009}{{Wright et~al.}}{{Wright, Yang, Ganesh, Sastry, and Ma}}}
\bibcite{yurtsever2017sketchy}{{31}{2017}{{Yurtsever et~al.}}{{Yurtsever, Udell, Tropp, and Cevher}}}
\bibstyle{plainnat}
\@writefile{toc}{\contentsline {section}{Appendix \numberline {A}Proof for Bias and Variance Analysis}{14}{Appendix.1.A}}
\newlabel{sec:appendix_proof}{{A}{14}{Proof for Bias and Variance Analysis}{Appendix.1.A}{}}
\newlabel{sec:appendix_proof@cref}{{[section][1][]A}{[1][14][]14}}
\newlabel{eq:row-length}{{A.1}{14}{Proof for Theorem \ref {thm: norm-preserve}}{equation.1.A.1}{}}
\newlabel{eq:row-length@cref}{{[equation][1][1]A.1}{[1][14][]14}}
\newlabel{eq:TRP_fourth_moment}{{A.1}{16}{Proof for Theorem \ref {thm:variance}}{equation.1.A.1}{}}
\newlabel{eq:TRP_fourth_moment@cref}{{[equation][1][1]A.1}{[1][16][]16}}
\newlabel{eq: inner_prod_unbias}{{A.2}{17}{Proof for Lemma \ref {lem:inner_product_TRP}}{equation.1.A.2}{}}
\newlabel{eq: inner_prod_unbias@cref}{{[equation][2][1]A.2}{[1][17][]17}}
\newlabel{eq:inner_prod_second_moment}{{A.2}{17}{Proof for Lemma \ref {lem:inner_product_TRP}}{equation.1.A.2}{}}
\newlabel{eq:inner_prod_second_moment@cref}{{[equation][2][1]A.2}{[1][17][]17}}
\@writefile{toc}{\contentsline {section}{Appendix \numberline {B}More Simulation Results}{20}{Appendix.1.B}}
\newlabel{appendix:more_result}{{B}{20}{More Simulation Results}{Appendix.1.B}{}}
\newlabel{appendix:more_result@cref}{{[section][2][]B}{[1][20][]20}}
\@writefile{toc}{\contentsline {paragraph}{Pairwise Distance Estimation}{20}{section*.12}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Average ratio of the pairwise distance for simulation data using Gaussian RP: \textit  {The plots correspond to the simulation for Gaussian RP, TRP, $\textup  {TRP}_5$ respectively with $n = 20, d = 2500, 10000, 40000$ and each data vector comes from $N(\mathbf  {0}, \mathbf  {I})$. The dashed line represents the error bar 2 standard deviation away from the average ratio.}\relax }}{20}{figure.caption.13}}
\newlabel{fig:gaussian}{{3}{20}{Average ratio of the pairwise distance for simulation data using Gaussian RP: \textit {The plots correspond to the simulation for Gaussian RP, TRP, $\textup {TRP}_5$ respectively with $n = 20, d = 2500, 10000, 40000$ and each data vector comes from $N(\mathbf {0}, \mathbf {I})$. The dashed line represents the error bar 2 standard deviation away from the average ratio.}\relax }{figure.caption.13}{}}
\newlabel{fig:gaussian@cref}{{[figure][3][]3}{[1][20][]20}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Average ratio of the pairwise distance for simulation data using Sparse RP: \textit  {The plots correspond to the simulation for Sparse RP, TRP, $\textup  {TRP}_5$ respectively with $n = 20, d = 2500, 10000, 40000$ and each data vector comes from $N(\mathbf  {0}, \mathbf  {I})$. The dashed line represents the error bar 2 standard deviation away from the average ratio.}\relax }}{20}{figure.caption.14}}
\newlabel{fig:sparse}{{4}{20}{Average ratio of the pairwise distance for simulation data using Sparse RP: \textit {The plots correspond to the simulation for Sparse RP, TRP, $\textup {TRP}_5$ respectively with $n = 20, d = 2500, 10000, 40000$ and each data vector comes from $N(\mathbf {0}, \mathbf {I})$. The dashed line represents the error bar 2 standard deviation away from the average ratio.}\relax }{figure.caption.14}{}}
\newlabel{fig:sparse@cref}{{[figure][4][]4}{[1][20][]20}}
\@writefile{toc}{\contentsline {paragraph}{Pairwise Cosine Similarity Estimation}{20}{section*.17}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Average ratio of the pairwise distance for simulation data using Very Sparse RP: \textit  {The plots correspond to the simulation for Very Sparse RP, TRP, $\textup  {TRP}_5$ respectively with $n = 20, d = 2500, 10000, 40000$ and each data vector comes from $N(\mathbf  {0}, \mathbf  {I})$. The dashed line represents the error bar 2 standard deviation away from the average ratio.}\relax }}{21}{figure.caption.15}}
\newlabel{fig:very_sparse}{{5}{21}{Average ratio of the pairwise distance for simulation data using Very Sparse RP: \textit {The plots correspond to the simulation for Very Sparse RP, TRP, $\textup {TRP}_5$ respectively with $n = 20, d = 2500, 10000, 40000$ and each data vector comes from $N(\mathbf {0}, \mathbf {I})$. The dashed line represents the error bar 2 standard deviation away from the average ratio.}\relax }{figure.caption.15}{}}
\newlabel{fig:very_sparse@cref}{{[figure][5][]5}{[1][20][]21}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Average ratio of the pairwise distance for simulation data using: \textit  {The plots correspond to the simulation for Gaussian, Sparase, Very Sparse RP, TRP, $\textup  {TRP}_5$ respectively with $n = 20, d = d_1d_2d_3 = 50 \times 50 \times 50 = 125000$ and each data vector comes from $N(\mathbf  {0}, \mathbf  {I})$. The dashed line represents the error bar 2 standard deviation away from the average ratio.}\relax }}{21}{figure.caption.16}}
\newlabel{fig:triple_krao}{{6}{21}{Average ratio of the pairwise distance for simulation data using: \textit {The plots correspond to the simulation for Gaussian, Sparase, Very Sparse RP, TRP, $\textup {TRP}_5$ respectively with $n = 20, d = d_1d_2d_3 = 50 \times 50 \times 50 = 125000$ and each data vector comes from $N(\mathbf {0}, \mathbf {I})$. The dashed line represents the error bar 2 standard deviation away from the average ratio.}\relax }{figure.caption.16}{}}
\newlabel{fig:triple_krao@cref}{{[figure][6][]6}{[1][20][]21}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces RMSE for the estimate of the pairwise inner product of the simulation data ($d = 10000, k = 50, n = 100 $), where standard error is in the parentheses. \relax }}{21}{table.caption.18}}
\newlabel{tbl:sim_inner_prod}{{2}{21}{RMSE for the estimate of the pairwise inner product of the simulation data ($d = 10000, k = 50, n = 100 $), where standard error is in the parentheses. \relax }{table.caption.18}{}}
\newlabel{tbl:sim_inner_prod@cref}{{[table][2][]2}{[1][20][]21}}
\@writefile{toc}{\contentsline {section}{Appendix \numberline {C}Appendix: Finite Sample Bound}{22}{Appendix.1.C}}
\newlabel{def:generalized-sub-exponential-mc}{{C.1}{22}{}{definition.1.C.1}{}}
\newlabel{def:generalized-sub-exponential-mc@cref}{{[definition][1][3]C.1}{[1][21][]22}}
\newlabel{eq:constant_in-sub-exponential}{{C.2}{23}{Proof for Proposition \ref {prop: N-2-bound}}{equation.1.C.2}{}}
\newlabel{eq:constant_in-sub-exponential@cref}{{[equation][2][3]C.2}{[1][22][]23}}
\newlabel{lemma:inner-product}{{C.1}{23}{}{thm.1.C.1}{}}
\newlabel{lemma:inner-product@cref}{{[lem][1][3]C.1}{[1][23][]23}}
\newlabel{eq:inner-bound}{{C.3}{23}{}{equation.1.C.3}{}}
\newlabel{eq:inner-bound@cref}{{[equation][3][3]C.3}{[1][23][]23}}
\citation{rudelson2013hanson}
\@writefile{toc}{\contentsline {section}{Appendix \numberline {D}Technical Lemmas}{24}{Appendix.1.D}}
\newlabel{def:sub-gaussian}{{D.1}{24}{}{definition.1.D.1}{}}
\newlabel{def:sub-gaussian@cref}{{[definition][1][4]D.1}{[1][23][]24}}
\newlabel{lemma:hanson_wright}{{D.1}{24}{}{thm.1.D.1}{}}
\newlabel{lemma:hanson_wright@cref}{{[lem][1][4]D.1}{[1][24][]24}}
\newlabel{lemma:hanson-wright-sub-exponential}{{D.2}{24}{}{thm.1.D.2}{}}
\newlabel{lemma:hanson-wright-sub-exponential@cref}{{[lem][2][4]D.2}{[1][24][]24}}
\newlabel{eq:sub-exponential-moment-condition}{{D.2}{24}{}{equation.1.D.2}{}}
\newlabel{eq:sub-exponential-moment-condition@cref}{{[lem][2][4]D.2}{[1][24][]24}}
\citation{buhler2002finding}
\newlabel{lemma:hanson-wright-sub-exponential-moment}{{D.3}{25}{}{thm.1.D.3}{}}
\newlabel{lemma:hanson-wright-sub-exponential-moment@cref}{{[lem][3][4]D.3}{[1][24][]25}}
